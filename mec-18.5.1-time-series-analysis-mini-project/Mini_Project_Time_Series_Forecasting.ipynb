{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8IkEZ1mF3MP"
   },
   "source": [
    "# Time Series Forecasting System\n",
    "Time Series is a big component of our everyday lives. They are in fact used in medicine (EEG analysis), finance (Stock Prices) and electronics (Sensor Data Analysis). Many Machine Learning models have been created in order to tackle these types of tasks, two examples are ARIMA (AutoRegressive Integrated Moving Average) models and RNNs (Recurrent Neural Networks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0a1a3jB3GYI8"
   },
   "source": [
    "# Data Source\n",
    "\n",
    "For Time series analysis, we are going to deal with Stock market Analysis. This dataset is based US-based stocks daily price and volume data.\n",
    "Dataset taken for analysis is IBM stock market data from 2006-01-01 to 2018-01-01.\n",
    "\n",
    "Below are the key fields in the dataset:\n",
    "\n",
    "__`Date, Open, High, Low, Close, Volume, Name`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJiCYDCPH0JX"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1SfYI6nebcN"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ftJJhAPH9ZJ"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "zLpZyyGucahj",
    "outputId": "c3cef8f3-bc13-42e6-f496-4096a13e4bd3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IBM_2006-01-01_to_2018-01-01.csv.zip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HqoaX9Zy8wvW",
    "outputId": "03cf2223-ec08-45fa-8803-714664d9fe6e"
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QL9CyyYg83ow",
    "outputId": "ffcc3cf0-1be9-4b2d-81d6-4023e849aeaf"
   },
   "outputs": [],
   "source": [
    "# Cleaning up the data\n",
    "df.isnull().values.any()\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "FXk5auRRh2O6",
    "outputId": "38ecc2d6-fb6f-405c-e6aa-72f2a59f9791"
   },
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df['Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDxYwSHoJmDP"
   },
   "source": [
    "# Note\n",
    "This dataset is composed of different features.We will just examine the “Open” stock prices feature. This same analysis can be repeated for most of the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piiRMy-_IIZv"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the High and Low prices of IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "c7B6d-PTfKuC",
    "outputId": "190fa06f-a8f0-413f-b94b-efab802c758d"
   },
   "outputs": [],
   "source": [
    "dr = df[['High', 'Low']]\n",
    "dr.plot()\n",
    "plt.title('IBM Returns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Visualize the Open and Close prices of IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "vWGWKmhKgJOr",
    "outputId": "c59eae5b-c44a-4333-9057-8fc405d01986"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Visualize the Open and Close Cumulative Prices of IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "8Cc0Zseff-4k",
    "outputId": "621dc52c-8621-45ef-a7f0-2d8c76fb7e73"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0nwpAKqKDfH"
   },
   "source": [
    "####  Before we start working on Time Series forecasting, Let's analyse the autocorrelation plot of the “Open” feature with respect to a few lag values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-correlation plot with Lag 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "ivjXx85Bf_h2",
    "outputId": "dd5ce4e7-8dc9-428e-a958-8e5b9ce42f80"
   },
   "outputs": [],
   "source": [
    "# START_CODE_HERE - plot the Autocorrelation plot for feature 'Open'\n",
    "from pandas.plotting import lag_plot\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "lag_plot(df['Open'], lag=1)\n",
    "plt.title('IBM Autocorrelation plot - Lag 1');\n",
    "# END_CODE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Visualize the Auto-Correlation plot for IBM Open prices with Lag 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "1BWxkN2ZhDGq",
    "outputId": "85296efa-0345-459e-a91e-adc3459c6def"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a definite linear trend in the auto-correlation plot telling us there is some correlation in prices with respect to prices from previous 1 / 5 days of lag which sets up the stage of forecasting future prices based on past price data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1n4_JM9Lhb5K"
   },
   "source": [
    "## Build Train-Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLTiykRpKh46"
   },
   "source": [
    "#### Now, Let's divide the data into a training and test set. Once done so, we can plot both on the same figure in order to get a feeling of how does our Time Series looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlEMHunIgLjE"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = df.iloc[0:int(len(df)*0.8), :], df.iloc[int(len(df)*0.8):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "nXQdYUp0isTi",
    "outputId": "8d99b465-1ca5-42ad-a9ff-9fa9c80ff3ff"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.title('IBM Prices')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.plot(train_data['Open'], 'blue', label='Training Data')\n",
    "plt.plot(test_data['Open'], 'green', label='Testing Data')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJhAHw6PKrQh"
   },
   "source": [
    "# ARIMA (AutoRegressive Integrated Moving Average)\n",
    "\n",
    "The acronym of ARIMA stands for:\n",
    "\n",
    "AutoRegressive(AR) = the model takes advantage of the connection between a predefined number of lagged observations and the current one.\n",
    "\n",
    "Integrated(I) = differencing between raw observations (eg. subtracting observations at different time steps).\n",
    "\n",
    "Moving Average(MA) = the model takes advantage of the relationship between the residual error and the observations.\n",
    "\n",
    "The ARIMA model makes use of three main parameters (p,d,q). These are:\n",
    "\n",
    "p = number of lag observations.\n",
    "\n",
    "d = the degree of differencing.\n",
    "\n",
    "q = the size of the moving average window.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ftf6yg95L7CR"
   },
   "source": [
    "## Understaning the ARIMA Model\n",
    "\n",
    "### the ARIMA parameters - used to help model the major aspects of a times series: seasonality, trend, and noise. These parameters are labeled p,d,and q. You have already learnt a fair bit of this in the curriculum but following is a brief refresher.\n",
    "\n",
    "__p:__ is the parameter associated with the auto-regressive aspect of the model, which incorporates past values. For example, forecasting that if it rained a lot over the past few days, you state its likely that it will rain tomorrow as well.\n",
    "\n",
    "__d:__ is the parameter associated with the integrated part of the model, which effects the amount of differencing to apply to a time series. You can imagine an example of this as forecasting that the amount of rain tomorrow will be similar to the amount of rain today, if the daily amounts of rain have been similar over the past few days.\n",
    "\n",
    "__q:__ is the parameter associated with the moving average part of the model.\n",
    "\n",
    "### Approach to determine the parameters\n",
    "There are many ways to choose these values statistically, such as looking at auto-correlation plots, correlation plots, domain experience, etc.\n",
    "\n",
    "Another approach is to perform a grid search over multiple values of p,d,q using some sort of performance criteria. The Akaike information criterion (AIC) is an estimator of the relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models.\n",
    "\n",
    "\n",
    "In this exercise, we will look into the statistical method of getting these values from auto-correlation and correlation plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iP5Qup5I7l0x"
   },
   "source": [
    "### Stationarity of the data - Determine the d value\n",
    "\n",
    "Stationarity typically indicates various statistical measures of the time series do not change over time. Thus, a time series is stationary when its mean, variance and auto-correlation, etc., are constant over time. \n",
    "\n",
    "Most time-series forecasting models typically perform well when the series is stationary and hence it is important to find out if your time-series dataset is stationary. \n",
    "\n",
    "ARIMAs that include differencing (i.e., d > 0) assume that the data becomes stationary after differencing. This is called difference-stationary. \n",
    "\n",
    "Auto-correlation plots are an easy way to determine whether your time series is sufficiently stationary for modeling. \n",
    "\n",
    "If the plot does not appear relatively stationary, your model will likely need a differencing term. \n",
    "\n",
    "The Augmented Dickey-Fuller test is an important statistical test which we will use to prove if the series is stationary or not and take necessary steps in case it is not stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "0TfnfVdMleJY",
    "outputId": "069bc3f8-aa6b-44f5-8c05-b5e31913d179"
   },
   "outputs": [],
   "source": [
    "window = 7\n",
    "train_series = train_data['Open']\n",
    "\n",
    "#Determing rolling statistics\n",
    "rolmean = train_series.rolling(window).mean()\n",
    "rolstd = train_series.rolling(window).std()\n",
    "\n",
    "#Plot rolling statistics:\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "orig = plt.plot(train_series, color='blue',label='Original')\n",
    "mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Mean & Standard Deviation');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "RM44jwLammeY",
    "outputId": "509bda4d-22da-43e7-cde6-bedbb0f24dce"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "dftest = adfuller(train_series, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "dfoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1YJhVNzZD87"
   },
   "source": [
    "If the p-value is small beyond a specific significance level threshold, let's consider that to be a standard value of 0.05, then we can say the series is stationary. F\n",
    "\n",
    "rom the above statistics, we can observe that the p-value is 0.539 which proves that our series is not stationary.\n",
    "\n",
    "To get stationary data, there are many techniques. We can use log, differencing and so on. Let's use a first order differencing here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Apply a first order differencing on the training data\n",
    "\n",
    "Hint: Check out the __`diff()`__ function in pandas and try using it on the __`train_series`__ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EomzoS5494th"
   },
   "outputs": [],
   "source": [
    "train_diff = <YOUR CODE HERE>\n",
    "train_diff = train_diff.dropna(inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Visualize Rolling statistics for differenced train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "kStK1sqjn_df",
    "outputId": "883dce6e-9e28-441d-d14b-aca927d7c283"
   },
   "outputs": [],
   "source": [
    "#Determing rolling statistics\n",
    "\n",
    "\n",
    "#Plot rolling statistics:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: Compute AD-Fuller Stats for differenced train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "OgNoMUJ1oE7V",
    "outputId": "01ee99ed-aa58-41eb-a54e-ad3a2a3c5f28"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-T_wDkhRZdqm"
   },
   "source": [
    "After differencing, the p-value is extremely small. Thus this series is very likely to be stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhY85n0qa85g"
   },
   "source": [
    "### ACF Plots (Auto Correlation Function):\n",
    "ACF is an auto-correlation function which gives us correlation of any series with its lagged values(previous timestep values).\n",
    "\n",
    "ACF plot describes the correlation of the current value with the previous lagged values(specified by *lags*).\n",
    "\n",
    "For example, how the dependency chain is followed as direct dependency .... $S_{t-2} --> S_{t-1} --> S_t$*\n",
    "\n",
    "Also, ACF finds correlation between $S_{t-2} --> S_t$ (indirect dependency).\n",
    "\n",
    "* --> = represents dependency\n",
    "\n",
    "#### Limitation: \n",
    "ACF is not very accurate as indirect dependency is affected by direct dependency and so the plots are always above the confidence band(as shown below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXEjp5BubI-L"
   },
   "source": [
    "### PACF Plots: Pearson Auto Correlation Function:\n",
    "PACF plots models the indirect dependencies and is not affected by the direct dependencies.\n",
    "\n",
    "$S_{t-2} --> S_t$\n",
    "\n",
    "From the below example we can see how today's value is affected by the last 10 days. \n",
    "\n",
    "The points that lie inside the blue confidence band do not correlate with or affect today's value. In ACF, we saw that all values are above the confidence band(as $S_{t-2} --> S{t}$ is affected by $S_{t-1} --> S_t$), which is not a good representation of the correlation.\n",
    "\n",
    "\n",
    "In PACF, indirect dependencies are modelled well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nG-g8DDZhL5"
   },
   "source": [
    "## ACF and PACF - AR and MA Intuition\n",
    "The partial autocorrelation at lag k is the correlation that results after removing the effect of any correlations due to the terms at shorter lags.\n",
    "\n",
    "### Autoregression Intuition\n",
    "Consider a time series that was generated by an autoregression (AR) process with a lag of k.\n",
    "\n",
    "We know that the ACF describes the autocorrelation between an observation and another observation at a prior time step that includes direct and indirect dependence information.\n",
    "\n",
    "This means we would expect the ACF for the AR(k) time series to be strong to a lag of k and the inertia of that relationship would carry on to subsequent lag values, trailing off at some point as the effect was weakened.\n",
    "\n",
    "We know that the PACF only describes the direct relationship between an observation and its lag. This would suggest that there would be no correlation for lag values beyond k.\n",
    "\n",
    "This is exactly the expectation of the ACF and PACF plots for an AR(k) process.\n",
    "\n",
    "### Moving Average Intuition\n",
    "Consider a time series that was generated by a moving average (MA) process with a lag of k.\n",
    "\n",
    "Remember that the moving average process is an autoregression model of the time series of residual errors from prior predictions. Another way to think about the moving average model is that it corrects future forecasts based on errors made on recent forecasts.\n",
    "\n",
    "We would expect the ACF for the MA(k) process to show a strong correlation with recent values up to the lag of k, then a sharp decline to low or no correlation. By definition, this is how the process was generated.\n",
    "\n",
    "For the PACF, we would expect the plot to show a strong relationship to the lag and a trailing off of correlation from the lag onwards.\n",
    "\n",
    "Again, this is exactly the expectation of the ACF and PACF plots for an MA(k) process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ACF and PACF on the original train series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "TKCS364Bq2BP",
    "outputId": "6c65562b-c492-4984-b2dd-edf97a2e682e"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12,8))\n",
    "plot_acf(train_series, ax=ax[0]); # \n",
    "plot_pacf(train_series, ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Plot ACF and PACF on the differenced train series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "FPxG3Hkwpl6u",
    "outputId": "74e69c20-903d-45f4-a111-ddfcc15af99a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4veOUVxSP8j"
   },
   "source": [
    "# How to determine p, d, q\n",
    "\n",
    "It's easy to determine d. In our case, we see the first order differencing make the ts stationary. Hence d = 1\n",
    "\n",
    "AR model might be investigated first with lag length selected from the PACF or via empirical investigation. In our case, it's clearly that within 5 lags the AR is significant. Which means, we can use AR = 5 i.e, p = 5\n",
    "\n",
    "To avoid the potential for incorrectly specifying the MA order to be too high we set MA = 0 i.e q = 0 by taking a look at the ACF plot though we do have a value of 5 which is significant considering the interval but we start off with the first lag value i.e q = 0.\n",
    "\n",
    "Hence:\n",
    "\n",
    "- p=5\n",
    "- d=1\n",
    "- q=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCEcnGXsdLkl"
   },
   "source": [
    "# Evaluation of ARIMA Model\n",
    "\n",
    "In order to evaluate the ARIMA model,we can use two different error functions:\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "\n",
    "SMAPE is commonly used as an accuracy measure based on relative errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iClH4YhNdSCB"
   },
   "source": [
    "### SMAPE\n",
    "\n",
    "![](imgs/smape.png)\n",
    "\n",
    "SMAPE is not currently supported in Scikit-learn as a loss function, therefore we first create this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v36vtXA1dZPo"
   },
   "outputs": [],
   "source": [
    "def smape_kun(y_true, y_pred):\n",
    "    # START_CODE_HERE\n",
    "    return np.mean((np.abs(y_pred - y_true) * 200 / (np.abs(y_pred) + np.abs(y_true))))\n",
    "    # END_CODE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: Difference the Test Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YRY19919xXD"
   },
   "outputs": [],
   "source": [
    "test_series = test_data['Open']\n",
    "test_diff = <YOUR CODE HERE>\n",
    "test_diff = test_diff.dropna(inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Train and Forecast using ARIMA Model by filling in the necessary blocks\n",
    "\n",
    "Note: Here we will use a rolling point-based prediction for the ARIMA model where we tried to predict every day's (t) stock price in the test data by using both the training data as well as the previous (n - t) days of test data also to fit the model.\n",
    "Of course this is not the only way for forecasting and you can do it in multiple ways e.g just use train data to forecast, use a window of days to forecast including test data and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_0v9P7OtoVu"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "IUvMaWIRg4VR",
    "outputId": "6dca97a1-65c1-4cc3-9adf-905995a54abe"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "history = [x for x in train_diff]\n",
    "\n",
    "predictions = list()\n",
    "for t in range(len(test_diff)):\n",
    "\n",
    "    # START_CODE_HERE - call the ARIMA Method with history and params\n",
    "    model = <YOUR CODE HERE>  # initialize the model with history and right order of parameters\n",
    "    model_fit = <YOUR CODE HERE>  # fit the model\n",
    "    # END_CODE_HERE\n",
    "\n",
    "    output = <YOUR CODE HERE>  # use forecast on the fitted model\n",
    "    yhat = output[0][0]\n",
    "    predictions.append(yhat)\n",
    "\n",
    "    obs = test_diff[t]\n",
    "    history.append(obs)\n",
    "\n",
    "    if t % 100 == 0:\n",
    "      print('Test Series Point: {}\\tPredicted={}, Expected={}'.format(t, yhat, obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Transform the forecasted values\n",
    "\n",
    "This is very important. Since we used differencing of the first order in the series before training, we need to reverse transform the values to get meaningful price forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "unArWBuS7o5z",
    "outputId": "cee241e1-e170-4063-e676-752fc5dbb70d"
   },
   "outputs": [],
   "source": [
    "reverse_test_diff = np.r_[test_series.iloc[0], test_diff].cumsum()\n",
    "reverse_predictions = np.r_[test_series.iloc[0], predictions].cumsum()\n",
    "reverse_test_diff.shape, reverse_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "NGDHu85n2clu",
    "outputId": "af8b3b73-5757-4c07-ba29-ed6a37ba0616"
   },
   "outputs": [],
   "source": [
    "error = mean_squared_error(reverse_test_diff, reverse_predictions)\n",
    "print('Testing Mean Squared Error: %.3f' % error)\n",
    "error2 = smape_kun(reverse_test_diff, reverse_predictions)\n",
    "print('Symmetric Mean absolute percentage error: %.3f' % error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVShn5zgMPcX"
   },
   "source": [
    "The loss results for this model are available above. According to the MSE, the model loss is quite low but for SMAPE is instead consistently higher. One of the main reason for this discrepancy is because SMAPE is commonly used loss a loss function for Time Series problems and can, therefore, provide a more reliable analysis. That showed there is still room for improvement of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5XoIrqDMe7c"
   },
   "source": [
    "## Let's Visualize the forecast results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3S7iMXv8nKg"
   },
   "outputs": [],
   "source": [
    "reverse_test_diff_series = pd.Series(reverse_test_diff)\n",
    "reverse_test_diff_series.index = test_series.index\n",
    "\n",
    "reverse_predictions_series = pd.Series(reverse_test_diff)\n",
    "reverse_predictions_series.index = test_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing train, test and forecast prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "LEBu1A6P8aJp",
    "outputId": "38f7847a-465b-4fa0-a14d-f5d78b70c5c5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.title('IBM Prices')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.plot(train_series, color='blue', label='Training Prices')\n",
    "plt.plot(reverse_test_diff_series, color='green', marker='.', label='Testing Prices - Reverse Diff Transform')\n",
    "plt.plot(reverse_test_diff_series, color='red', linestyle='--', label='Forecasted Prices - Reverse Diff Transform')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Visualize only test and forecast prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "fOKhtSM79hM_",
    "outputId": "694f2659-1a0e-4665-d453-132bba6cda28"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8k-cTIUyMzd_"
   },
   "source": [
    "This analysis using ARIMA has performed pretty well in forecasting prices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcM7rwQFCqHL"
   },
   "source": [
    "# Time Series Forecasting with Deep Learning\n",
    "\n",
    "The approach uses sequential models, to be more specific - LSTMs, to build a deep learning model that predicts the 'Open' Stock prices of IBM over a period of two years by using data from the previous 10 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ege_yD9YDmSN"
   },
   "source": [
    "### LSTM: A brief overview\n",
    "\n",
    "What are LSTMs? : https://medium.com/deep-math-machine-learning-ai/chapter-10-1-deepnlp-lstm-long-short-term-memory-networks-with-math-21477f8e4235\n",
    "\n",
    "Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A RNN composed of LSTM units is often called an LSTM network. A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for \"remembering\" values over arbitrary time intervals; hence the word \"memory\" in LSTM. Each of the three gates can be thought of as a \"conventional\" artificial neuron, as in a multi-layer (or feedforward) neural network: that is, they compute an activation (using an activation function) of a weighted sum. Intuitively, they can be thought as regulators of the flow of values that goes through the connections of the LSTM; hence the denotation \"gate\". There are connections between these gates and the cell.\n",
    "\n",
    "The expression long short-term refers to the fact that LSTM is a model for the short-term memory which can last for a long period of time. An LSTM is well-suited to classify, process and predict time series given time lags of unknown size and duration between important events. LSTMs were developed to deal with the exploding and vanishing gradient problem when training traditional RNNs.\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Long_short-term_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8hK0f8wb79O"
   },
   "source": [
    "### Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4Fo2a_Rg5_w"
   },
   "outputs": [],
   "source": [
    "# Let's load the libraries and dependencies for the deep learning model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VuF5ziiYcDD-"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "loos_QCqjZl8",
    "outputId": "8db32178-6d24-41a5-aca4-c8886d2ad4d0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IBM_2006-01-01_to_2018-01-01.csv\")\n",
    "df.isnull().values.any()\n",
    "df = df.dropna()\n",
    "\n",
    "df.index = pd.to_datetime(df['Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeR4wBTNSAUX"
   },
   "source": [
    "# Note\n",
    "This dataset is composed of different features.we will just examine the \"Open\" stock prices feature. This same analysis can be repeated for most of the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nvliw7fqMCcF"
   },
   "source": [
    "## Build Train-Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e51pJz3Ajs0u",
    "outputId": "9d7fa2bd-044f-4f6f-cc4d-8930eb8b61f5"
   },
   "outputs": [],
   "source": [
    "# Splitting the train and test set considering 'Open' feature from the dataset\n",
    "train_data, test_data = df.iloc[0:int(len(df)*0.8), :], df.iloc[int(len(df)*0.8):, :]\n",
    "train_series = train_data['Open']\n",
    "test_series = test_data['Open']\n",
    "train_series.shape, test_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSp2L8YIMfKN"
   },
   "source": [
    "### Q11: Visualize train and test price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "gBnSZGfSj6Cs",
    "outputId": "6e071f16-4d78-413f-b175-37e8cb603955"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8f0sPbUMvg7"
   },
   "source": [
    "### Scaling\n",
    "As stock prices can vary across a wide range, we scale the data to have zero mean and unit variance.\n",
    "\n",
    "This is done to ensure that the gradient descent is sooner when learning a deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12: Use the initialized min-max scaler to scale the prices in train_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7D3Hvo_kC2F"
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "# START_CODE_HERE\n",
    "training_set_scaled = <YOUR CODE HERE>\n",
    "# END_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Rms7Nr3LIeuV",
    "outputId": "5a92caf3-f015-44c1-fbe5-e7451ba445eb"
   },
   "outputs": [],
   "source": [
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEaPD_p2Nu87"
   },
   "source": [
    "### Train Data Preparation\n",
    "\n",
    "Train data uses the previous 60 days (two months) data to predict the stock price of the next day.\n",
    "The data is prepared just like a sliding window approach, where\n",
    "*window_size = 60*\n",
    "\n",
    "Sample image for sliding window:\n",
    "![Sliding window](imgs/sliding_window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3LHfiLnhkGpN",
    "outputId": "278d904e-00b5-44fd-9ca9-cc6bc37c7249"
   },
   "outputs": [],
   "source": [
    "#1 output and 60 values inputs\n",
    "# So for each element of training set (output), we have 60 previous training set elements (input)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdzzWChQROAg"
   },
   "source": [
    "#### Reshape X_train\n",
    "\n",
    "Now we reshape X_train in the format like:\n",
    "\n",
    "(batch_size, timesteps, input_dim) => (m, features, $x_{i1}$)\n",
    "\n",
    "The X_train should be now: (2709, 60, 1)\n",
    "\n",
    "60 features = 60 day sliding window\n",
    "\n",
    "$x_{i1}$ = 1 data point for each feature and i represents the feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQRlDlXMkKCV"
   },
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modeling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I_FLbtZkT-RF",
    "outputId": "70bd8ffd-f73b-4091-ef7f-d594ec30873b"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIrlm79SVn5i"
   },
   "source": [
    "### LSTM Regression model\n",
    "\n",
    "We use  [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM):\n",
    "*   units - output dimensions\n",
    "*   return_sequences is set to True to get all the hidden state vectors information\n",
    "\n",
    "The model uses 2 LSTM layers followed by a Dense Layer with a single neuron to output regression prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1gSynqKGGPJ"
   },
   "source": [
    "#### Similar Model Architecture (dimensions not exact)\n",
    "\n",
    "![Similar Model Architecture](imgs/lstm.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13: Build the LSTM based forecasting DL Model architecture\n",
    "\n",
    "Hints:\n",
    "\n",
    "    - Fill the second LSTM layer using an LSTM cell with 64 units, remember NOT to set return_sequences to True as we are only concerned about passing the last sequence output to the next layer\n",
    "    - Fill the Output layer with 1 unit\n",
    "    - Compile the model with mentioned optimizer and loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "Vhe8p4iqkPfB",
    "outputId": "682d878c-bdd6-4d28-e72a-1b8cb3c3f24b"
   },
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "# First LSTM layer with Dropout regularisation\n",
    "regressor.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Second LSTM layer\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "# The output layer\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "# Compiling the RNN - optimizer(rmsprop)and loss(mean squared error)\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "MBRin4eMAsT_",
    "outputId": "91760fb0-6085-42c1-f507-8adf135eadb6"
   },
   "outputs": [],
   "source": [
    "regressor.fit(X_train,y_train, epochs=15, batch_size=64, validation_split=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXyIJG9vauFj"
   },
   "source": [
    "### Test Data Forecasting\n",
    "\n",
    "#### Data Preparation:\n",
    "Lets prepare the test data just like we did with the train data.\n",
    "\n",
    "Remember to start forecasting on the first day of the test data, we need the last 60 days of train data.\n",
    "\n",
    "Thus, the following steps have been performed so first 60 entires of test set have 60 previous values from the train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14: Get the last 60 records from train_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4mLalxGGCxzf",
    "outputId": "1df0414a-9ab3-4443-e527-ca56226c674e"
   },
   "outputs": [],
   "source": [
    "train_last60 = <YOUR CODE HERE>\n",
    "print(train_last60.shape)\n",
    "assert train_last60.shape == (60,), (\"Oops! There is a data dimension mismatch error. Hint: Slice the last 60 records from train_series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vhfLNVCnCrNE",
    "outputId": "7c6324e3-572a-491a-e8e8-ab7b9ec99e91"
   },
   "outputs": [],
   "source": [
    "test_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q15: Combine both train_last60 and test_series together \n",
    "\n",
    "Hint: Check pandas __`concat()`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_XrJWDeZC_nG",
    "outputId": "2ceb51ec-08f9-440b-a6be-9cfc26883ab5"
   },
   "outputs": [],
   "source": [
    "new_test_series =  <YOUR CODE HERE>\n",
    "print(new_test_series.shape)\n",
    "assert new_test_series.shape == (664,), (\"Oops! There is a data dimension mismatch error. Hint: Use pandas concat with the right axis parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16: Scale the test dataset (new_test_series) using the trained MinMaxScaler transformer - sc\n",
    "\n",
    "Hint: Don't fit the scaler again here since it has already been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6EEBJmFkRsB"
   },
   "outputs": [],
   "source": [
    "test_set_scaled = <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test dataset Windows of 60  days each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ja7H-jR0kWvX",
    "outputId": "ccc648fb-249a-4fd0-b4d7-a6f9ae827a0b"
   },
   "outputs": [],
   "source": [
    "# Preparing X_test and predicting the prices\n",
    "X_test = []\n",
    "for i in range(60,len(test_set_scaled)):\n",
    "    X_test.append(test_set_scaled[i-60:i,0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction and Reverse Transform of Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BBQ-3C53DZ5W",
    "outputId": "8beb0870-626b-4e77-bcae-3d8b05107a0d"
   },
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price_revtrans = sc.inverse_transform(predicted_stock_price).ravel()\n",
    "predicted_stock_price_revtrans_series = pd.Series(predicted_stock_price_revtrans)\n",
    "predicted_stock_price_revtrans_series.index = test_series.index\n",
    "predicted_stock_price_revtrans_series.shape, test_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dhjde2l_Dx1y"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "iLDpDXl5kcnH",
    "outputId": "16f9238f-2d13-4c19-bed3-b3281f0388b7"
   },
   "outputs": [],
   "source": [
    "# Evaluating our model\n",
    "error = mean_squared_error(test_series, predicted_stock_price_revtrans_series)\n",
    "print('Testing Mean Squared Error: %.3f' % error)\n",
    "error2 = smape_kun(test_series, predicted_stock_price_revtrans_series)\n",
    "print('Symmetric Mean absolute percentage error: %.3f' % error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tR06LgzkD58c"
   },
   "source": [
    "## Visualizing the results from model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize train, test and forecasted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "g32mqimHkYja",
    "outputId": "c998166f-1e23-4aac-d1bf-98ee4bfe82ee"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.title('IBM Prices')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.plot(train_series, color='blue', label='Training Prices')\n",
    "plt.plot(test_series, color='green', label='Testing Prices')\n",
    "plt.plot(predicted_stock_price_revtrans_series, color='red', linestyle='--', label='Forecasted Prices - Reverse Transform')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17: Visualize only test and forecast prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "UH7f5oS8Fqxy",
    "outputId": "25bb2da0-b464-4a96-f357-41fead67b1ba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1xuGfJuQTOp"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Remember we did a rolling point-based prediction for the ARIMA model where we tried to predict every day's (t) stock price in the test data by using both the training data as well as the previous (n - t) days of test data also to fit the model which gave it such good results vs. the LSTM model where we used 2 months of rolling window price data to predict the next day's price."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Time_Series_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}